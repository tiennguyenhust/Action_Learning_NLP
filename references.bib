@article{Marcu2009,
abstract = {In recent years, IT Service Management (ITSM) has become one of the most researched areas of IT. Incident and Problem Management are two of the Service Operation processes in the IT Infrastructure Library (ITIL). These two processes aim to recognize, log, isolate and correct errors which occur in the environment and disrupt the delivery of services. Incident Management and Problem Management form the basis of the tooling provided by an Incident Ticket Systems (ITS). In an ITS system, seemingly unrelated tickets created by end users and monitoring systems can coexist and have the same root cause. The connection between failed resource and malfunctioning services is not realized automatically, but often established manually by means of human intervention. This need for human involvement reduces productivity. The introduction of automation would increase productivity and therefore reduce the cost of incident resolution In this paper, we propose a model to correlate incident tickets based on three criteria. First, we employ a category-based correlation that relies on matching service identifiers with associated resource identifiers, using similarity rules. Secondly, we correlate the configuration items which are critical to the failed service with the earlier identified resource tickets in order to optimize the topological comparison. Finally, we augment scheduled resource data collection with constraint adaptive probing to minimize the correlation interval for temporally correlated tickets. We present experimental data in support of our proposed correlation model. {\textcopyright} 2009 IEEE.},
author = {Marcu, Patricia and Grabarnik, Genady and Luan, Laura and Rosu, Daniela and Shwartz, Larisa and Ward, Chris},
doi = {10.1109/INM.2009.5188863},
file = {:Users/alexanderpoppe/OneDrive - EPITA/Courses/Thesis/inm.2009.5188863.pdf:pdf},
isbn = {9781424434879},
journal = {2009 IFIP/IEEE International Symposium on Integrated Network Management, IM 2009},
keywords = {Incident management,Incident ticket},
pages = {569--576},
title = {{Towards an optimized model of incident ticket correlation}},
year = {2009}
}
@misc{Garrett2020,
author = {Garrett, Eichhorn},
booktitle = {towards data science},
title = {{Predict IT Support Tickets with Machine Learning and NLP | by Garrett Eichhorn | Towards Data Science}},
url = {https://towardsdatascience.com/predict-it-support-tickets-with-machine-learning-and-nlp-a87ee1cb66fc},
urldate = {2021-07-05},
year = {2020}
}
@misc{Rajput2020,
author = {Rajput, Ajit},
booktitle = {Medium},
title = {{Natural Language Processing for IT Support Incidents | by Ajit Rajput | Analytics Vidhya | Medium}},
url = {https://medium.com/analytics-vidhya/natural-language-processing-for-it-support-incident-51cb35af0735},
urldate = {2021-07-05},
year = {2020}
}
@misc{Eichhorn2020,
author = {Eichhorn, Garett},
booktitle = {Medium},
title = {{Predict IT Support Tickets with Machine Learning and NLP | by Garrett Eichhorn | Towards Data Science}},
url = {https://towardsdatascience.com/predict-it-support-tickets-with-machine-learning-and-nlp-a87ee1cb66fc},
urldate = {2021-07-03},
year = {2020}
}
@misc{KMeans,
title = {{sklearn.cluster.KMeans — scikit-learn 0.24.2 documentation}},
url = {https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html},
urldate = {2021-07-15}
}
@misc{NLP,
title = {{Natural Language Toolkit — NLTK 3.6.2 documentation}},
url = {http://www.nltk.org/},
urldate = {2021-07-15}
}
@article{Syeda2017,
abstract = {In this work, we focus accident causation for the railway industry by exploiting text analysis approaches mainly Natural Language Processing (NLP). We review and analyse investigation reports of railway accidents in the UK published by the Rail Accident Investigation Branch (RAIB), aiming to unleash the presence of entities which are informative of causes and failures such as human, technical and external. We give an overview of framework based on NLP and machine learning to analyse the raw text from RAIB reports which would assist risk and incident analysis experts to study causal relationship between causes and failures towards overall safety in rail industry. The approach can also be generalized to other safety critical domains such as aviation etc.},
author = {Syeda, Kanza Noor and Shirazi, Syed Noorulhassan and Asad, Syed and Naqvi, Ali and Parkinson, Howard J},
file = {:Users/alexanderpoppe/OneDrive - EPITA/Courses/Thesis/Exploiting-Natural-Language-Processing-for-Analysing-Railway-Incident-Reports.pdf:pdf},
journal = {IGI Global Publishing},
keywords = {Railway safety,accident causation model,incident analysis,rail},
pages = {1--18},
title = {{Exploiting Natural Language Processing for Analysing Railway Incident Reports}},
url = {http://www.digitalrail.co.uk/wp-content/uploads/2018/01/Exploiting-Natural-Language-Processing-for-Analysing-Railway-Incident-Reports.pdf},
year = {2017}
}
@misc{ELKLog,
title = {{Sending Logs to ELK with Winlogbeat and Sysmon – Burnham Forensics}},
url = {https://burnhamforensics.com/2018/11/18/sending-logs-to-elk-with-winlogbeat-and-sysmon/},
urldate = {2021-07-15}
}
@misc{ELK,
title = {{The ELK stack}},
url = {https://aws.amazon.com/elasticsearch-service/the-elk-stack/},
urldate = {2021-07-15}
}
@misc{DataVizImportance,
title = {{Importance, Purpose, and Benefit of Data Visualization Tools!}},
url = {https://splashbi.com/importance-purpose-benefit-of-data-visualization-tools/},
urldate = {2021-07-15}
}
@article{Sonntag,
abstract = {We follow an empirical approach from data quality toward text quality, where the expectations of the consumer, human or machine, take the centre stage. We try to obtain numerical text quality statements which must be interpreted for the expectations of the user and suitability for automatic natural language processing (NLP) separately. We state that apart from text accessibility today only representational text quality metrics can be derived and computed automatically. Interestingly, text quality for NLP traces back to questions of text representation.},
author = {Sonntag, Daniel},
file = {:Users/alexanderpoppe/Library/Application Support/Mendeley Desktop/Downloaded/Sonntag - Unknown - Assessing the quality of natural language text data.pdf:pdf},
title = {{Assessing the quality of natural language text data}}
}
@article{Azeroual,
abstract = {In the implementation and use of research information systems (RIS) in scientific institutions, text data mining and semantic technologies are a key technology for the meaningful use of large amounts of data. It is not the collection of data that is difficult, but the further processing and integration of the data in RIS. Data is usually not uniformly formatted and structured, such as texts and tables that can not be linked. These include various source systems with their different data formats such as project and publication databases, CERIF and RCD data model, etc. Internal and external data sources continue to develop. On the one hand, they must be constantly synchronized and the results of the data links checked. On the other hand, the texts must be processed in natural language and certain information extracted. Using text data mining, the quality of the metadata is analyzed and this identifies the entities and general keywords. So that the user is supported in the search for interesting research information. The information age makes it easier to store huge amounts of data and increase the number of documents on the internet, in institutions' intranets, in newswires and blogs is overwhelming. Search engines should help to specifically open up these sources of information and make them usable for administrative and research purposes. Against this backdrop, the aim of this paper is to provide an overview of text data mining techniques and the management of successful data quality for RIS in the context of open data and open science in scientific institutions and libraries, as well as to provide ideas for their Format de pr{\'{e}}sentation de la communication au colloque icoa2018 2 application. In particular, solutions for the RIS will be presented.},
author = {Azeroual, Otmane and Saake, Gunter and Abuosba, Mohammad and Sch{\"{o}}pfel, Joachim},
file = {:Users/alexanderpoppe/Library/Application Support/Mendeley Desktop/Downloaded/Azeroual et al. - Unknown - Text data mining and data quality management for research information systems in the context of open data an.pdf:pdf},
keywords = {Big data,Current research information systems (CRIS),Data mining,Data quality management,Knowledge discovery database,Open data,Open science,Research information,Research information systems (RIS),Standardization,Text analysis},
title = {{Text data mining and data quality management for research information systems in the context of open data and open science}}
}
@misc{GMM,
title = {{Gaussian Mixture Models | Clustering Algorithm Python}},
url = {https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/},
urldate = {2021-07-15}
}
@article{Zhang1996,
abstract = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs. This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively. We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.},
author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
doi = {10.1145/235968.233324},
journal = {SIGMOD Record (ACM Special Interest Group on Management of Data)},
number = {2},
pages = {103--114},
publisher = {Association for Computing Machinery (ACM)},
title = {{BIRCH: An Efficient Data Clustering Method for Very Large Databases}},
volume = {25},
year = {1996}
}
@misc{IntroNLP,
title = {{What is Natural Language Processing? Intro to NLP in Machine Learning}},
url = {https://www.gyansetu.in/what-is-natural-language-processing/},
urldate = {2021-07-15}
}
@misc{NLPWiki,
title = {{Natural language processing - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Natural_language_processing},
urldate = {2021-07-16}
}
@misc{KMeanWiki,
mendeley-groups = {Thesis NLP},
title = {{k-means clustering - Wikipedia}},
url = {https://en.wikipedia.org/wiki/K-means_clustering},
urldate = {2021-07-16}
}
@article{TsengYuen-Hsien2010,
abstract = {Document clustering is a powerful technique to detect topics and their relations for information browsing, analysis, and organization. However, clustered documents require post-assignment of descri...},
author = {TsengYuen-Hsien},
doi = {10.1016/J.ESWA.2009.07.048},
journal = {Expert Systems with Applications: An International Journal},
keywords = {Clustering labeling,Correlation coefficient,Hypernym search,Topic identification,WordNet},
month = {mar},
number = {3},
pages = {2247--2254},
publisher = {
		Pergamon Press, Inc.
		PUB1185
		Elmsford, NY, USA
	},
title = {{Generic title labeling for clustered documents}},
url = {https://dl.acm.org/doi/abs/10.1016/j.eswa.2009.07.048},
volume = {37},
year = {2010}
}
@article{MinhLeKazuhiroOgata2019,
author = {{Minh Le Kazuhiro Ogata}, Nguyen},
file = {:Users/alexanderpoppe/Library/Application Support/Mendeley Desktop/Downloaded/Minh Le Kazuhiro Ogata - 2019 - Master's Thesis Applying Clustering Techniques for Refining Large Data Set (Case Study on Malware) 17104.pdf:pdf},
mendeley-groups = {Thesis NLP},
title = {{Master's Thesis Applying Clustering Techniques for Refining Large Data Set (Case Study on Malware) 1710443 Yoon Myet Thwe Supervisor Mizuhito Ogawa Main Examiner Mizuhito Ogawa Examiners Nao Hirokawa}},
year = {2019}
}